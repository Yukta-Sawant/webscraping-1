{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VODDZnX9AZ6-",
        "outputId": "bd677187-93a8-40c0-c338-ddb1c2ede6f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting BeautifulSoup\n",
            "  Using cached BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "pip install BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tctfMeLjKbwd",
        "outputId": "2e9e15df-72fc-4d63-8583-176da2829834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "QPi7o4BoEFO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "CmXM0R7NEH4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "K0bHHBTsBWFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Put some skill that you are not familiar with')\n",
        "unfamiliar_skill=input('>')\n",
        "print(f'Filtering out {unfamiliar_skill}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZqV_Uc0Bd7c",
        "outputId": "97751615-e330-4e33-8c72-34679a1d5555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Put some skill that you are not familiar with\n",
            ">abcd\n",
            "Filtering out abcd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_jobs():\n",
        "  html_text=requests.get('https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=python&txtLocation=')\n",
        "  soup=BeautifulSoup(html_text.text,'lxml')\n",
        "  jobs=soup.find_all('li',class_='clearfix job-bx wht-shd-bx')\n",
        "  for index,job in enumerate(jobs):\n",
        "    published_date=job.find('span',class_='sim-posted').span.text\n",
        "    if 'few' in published_date:\n",
        "      company_name=job.find('h3',class_='joblist-comp-name').text.replace(' ','')\n",
        "      skills=job.find('span',class_='srp-skills').text.replace(' ','')\n",
        "      more_info=job.header.h2.a['href']\n",
        "      if unfamiliar_skill not in skills:\n",
        "        print('a')\n",
        "        with open(f'post/{index}.txt','w') as f:\n",
        "          f.write(f'Company Name:{company_name}')\n",
        "          f.write(f'Required skill:{skills}')\n",
        "          f.write(f'More Info:{more_info}')\n",
        "          print(f'File saved :{index}')\n",
        "\n",
        "if __name__=='__main__':\n",
        "  while True:\n",
        "    find_jobs()\n",
        "    time_wait=1\n",
        "    print(f'Waiting {time_wait} minutes...')\n",
        "    time.sleep(time_wait*60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BU0oxfeZEihR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}